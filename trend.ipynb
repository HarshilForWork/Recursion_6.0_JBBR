{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('uptownfunk.json', 'r') as file:\n",
    "    uptownfunk_data = json.load(file)\n",
    "\n",
    "# Extract unique words from the JSON content\n",
    "keywords = list(set(word.lower() for entry in uptownfunk_data if 'text' in entry for word in entry['text'].split()))\n",
    "regions = [\n",
    "    \"IN\" \n",
    "]\n",
    "timeframe = \"now 7-d\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'break', 'down', 'gold', 'hood', 'doh', 'out', 'man', 'jar', 'liquor', 'what', 'leave', 'gotta', 'myself,', 'sign', 'chucks', 'than', 'am', 'hollywood,', \"it's\", 'good', 'dragon', 'retire,', 'and', 'brag', 'them', \"wildin'\", 'so', 'girls', 'name,', 'hot', 'stop', 'say', 'lemme', 'watch,', 'get', 'wanna', 'hallelujah,', 'i', 'stretch', 'jackson,', 'said', 'julio,', \"stylin',\", \"don't\", 'harlem,', 'up,', 'up', 'show', 'something', 'just', 'know', 'then', 'dance,', 'own', 'you,', 'about', 'ride', 'called', 'flaunt', 'bitch,', 'white', 'put', 'believe', 'smoother', 'me', 'you', 'masterpieces', 'it', 'jump', \"y'all\", 'michelle', 'on,', 'straight', \"'bout\", 'who', 'to', 'fresh', 'saturday', 'my', 'tell', 'hit', 'come', 'doh,', 'the', 'ooh', 'damn', 'if', 'money', 'kiss', 'funk', 'hit,', 'too', 'it,', 'of', 'mississippi', 'minute', 'spot', 'give', 'city', 'â™ª', 'police', \"i'm\", 'saint', 'make', 'before', 'fireman', 'hey,', 'one,', 'that', 'take', \"livin'\", 'night,', 'got', 'damn,', 'with', 'cup,', \"gon'\", 'watch', 'on', 'some', 'pfeiffer,', 'fill', 'uptown', 'freaky', 'well,', 'a', 'me,', 'sexy', 'wait', 'for', 'check', 'in', 'bad', 'your', 'oh', 'cold', \"'cause\", 'laurent', 'this', 'sip,', 'girls,', 'pretty', 'skippy', \"lil'\", 'ice', 'we'}\n"
     ]
    }
   ],
   "source": [
    "# Extract unique words from the JSON content, convert to lowercase, and create a set\n",
    "print(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_keywords(keywords, chunk_size):\n",
    "    \"\"\"\n",
    "    Splits a list of keywords into chunks of a specified size.\n",
    "    \n",
    "    Args:\n",
    "        keywords (list): List of keywords to split.\n",
    "        chunk_size (int): Size of each chunk.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of keyword chunks.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(keywords), chunk_size):\n",
    "        yield keywords[i:i + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_search_trends(keywords, regions, timeframe):\n",
    "    \"\"\"\n",
    "    Analyzes search trends for given keywords and regions with delays to avoid rate limits.\n",
    "    \n",
    "    Args:\n",
    "        keywords (list): List of keywords to analyze (up to 5 per request).\n",
    "        regions (list): List of region codes (e.g., 'US', 'UK').\n",
    "        timeframe (str): Timeframe for trends (e.g., 'today 5-y').\n",
    "    \n",
    "    Returns:\n",
    "        dict: Trend data for each region.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)  # Initialize pytrends\n",
    "    all_data = {}\n",
    "\n",
    "    # Split keywords into chunks of 5\n",
    "    keyword_chunks = chunk_keywords(keywords, chunk_size=5)\n",
    "\n",
    "    for region in regions:\n",
    "        for chunk in keyword_chunks:\n",
    "            try:\n",
    "                # Build payload and fetch data\n",
    "                pytrends.build_payload(chunk, cat=0, timeframe=timeframe, geo=region)\n",
    "                data = pytrends.interest_over_time()\n",
    "                if not data.empty:\n",
    "                    if region not in all_data:\n",
    "                        all_data[region] = data\n",
    "                    else:\n",
    "                        all_data[region] = all_data[region].join(data, how='outer')\n",
    "                \n",
    "                # Pause for 5 seconds to respect rate limits\n",
    "                time.sleep(5)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {region} with keywords {chunk}: {e}\")\n",
    "                # Wait longer if an error occurs, then continue\n",
    "                time.sleep(10)\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IN with keywords ['break', 'gold', 'hood', 'down', 'doh']: The request failed: Google returned a response with code 429\n",
      "Error fetching data for IN with keywords ['out', 'man', 'jar', 'liquor', 'what']: The request failed: Google returned a response with code 429\n",
      "Error fetching data for IN with keywords ['leave', 'gotta', 'myself,', 'sign', 'chucks']: The request failed: Google returned a response with code 429\n",
      "Error fetching data for IN with keywords ['than', 'am', 'hollywood,', \"it's\", 'good']: The request failed: Google returned a response with code 429\n",
      "Error fetching data for IN with keywords ['dragon', 'retire,', 'and', 'brag', 'them']: The request failed: Google returned a response with code 429\n",
      "Error fetching data for IN with keywords [\"wildin'\", 'so', 'girls', 'name,', 'hot']: The request failed: Google returned a response with code 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m, in \u001b[0;36manalyze_search_trends\u001b[1;34m(keywords, regions, timeframe)\u001b[0m\n\u001b[0;32m     23\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(chunk, cat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, timeframe\u001b[38;5;241m=\u001b[39mtimeframe, geo\u001b[38;5;241m=\u001b[39mregion)\n\u001b[1;32m---> 24\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytrends\\request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytrends\\request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[1;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Execute analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trend_data \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_search_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m region, data \u001b[38;5;129;01min\u001b[39;00m trend_data\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[28], line 37\u001b[0m, in \u001b[0;36manalyze_search_trends\u001b[1;34m(keywords, regions, timeframe)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with keywords \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;66;03m# Wait longer if an error occurs, then continue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Execute analysis\n",
    "trend_data = analyze_search_trends(keywords, regions, timeframe)\n",
    "\n",
    "# Display results\n",
    "for region, data in trend_data.items():\n",
    "    print(f\"Trends for {region}:\")\n",
    "    print(data.head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
